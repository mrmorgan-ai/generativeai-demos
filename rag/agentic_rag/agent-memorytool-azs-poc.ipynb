{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-projects azure-search-documents requests python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to generate document embedding\n",
    "def generate_embedding(text: str):\n",
    "    # Generate embeddings for the provided text using the specified model\n",
    "    embeddings_response = client.embeddings.create(\n",
    "        model=AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME, input=text\n",
    "    )\n",
    "    # Extract the embedding data from the response\n",
    "    return embeddings_response.data[0].embedding\n",
    "# Generate an embedding for the provided text\n",
    "generate_embedding(\"I love Azure AI Search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.ai.projects.models import AzureAISearchTool\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    AzureOpenAIModelName,\n",
    ")\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "AZURE_CONNECTION_STRING = os.getenv(\"AZURE_CONNECTION_STRING\")\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "OPENAI_EMBEDDINGS_ENDPOINT = os.getenv(\"AZURE_INFERENCE_ENDPOINT\")  # e.g. \"https://<hostname>.openai.azure.com/openai/deployments/<deployment>\"\n",
    "OPENAI_EMBEDDINGS_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")  # if key-based auth\n",
    "# We'll default to 1536 (common for e.g. text-embedding-ada-002), you can adjust if needed\n",
    "EMBEDDING_DIM = 1536\n",
    "\n",
    "# By user request, we'll use index name: \"azure-search-docs\"\n",
    "MEMORY_INDEX_NAME = \"memory-index\"\n",
    "VECTOR_FIELD = \"embedding\"  # name of the field storing vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import EmbeddingsClient\n",
    "\n",
    "# We can do key-based authentication by default\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "try:\n",
    "    embeddings_client = EmbeddingsClient(\n",
    "        endpoint=OPENAI_EMBEDDINGS_ENDPOINT,\n",
    "        credential=AzureKeyCredential(OPENAI_EMBEDDINGS_KEY),\n",
    "        api_version=\"2024-06-01\"  # or whichever is valid for your Azure OpenAI resource\n",
    "    )\n",
    "    print(\"EmbeddingsClient successfully created.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to create EmbeddingsClient. Check your endpoint/key. Error:\", e)\n",
    "    embeddings_client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_memory_index():\n",
    "    \"\"\"\n",
    "    Minimal schema with:\n",
    "      - id (key)\n",
    "      - threadId (filterable)\n",
    "      - role\n",
    "      - content\n",
    "      - embedding (vector)\n",
    "    We'll do a basic vectorSearch config with EKNN.\n",
    "    \"\"\"\n",
    "    index_client = SearchIndexClient(\n",
    "        endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        credential=AzureKeyCredential(AZURE_SEARCH_API_KEY),\n",
    "    )\n",
    "\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SimpleField(name=\"threadId\", type=SearchFieldDataType.String, filterable=True),\n",
    "        SimpleField(name=\"role\", type=SearchFieldDataType.String, filterable=True),\n",
    "        SearchableField(\n",
    "            name=\"content\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            analyzer_name=\"standard.lucene\",\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=VECTOR_FIELD,\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=EMBEDDING_DIM,\n",
    "            vector_search_profile_name=\"my-vector-profile\",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    vector_search = VectorSearch(\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"my-vector-profile\",\n",
    "                algorithm_configuration_name=\"my-eknn\",\n",
    "                vectorizer_name=\"my-vectorizer\",\n",
    "            )\n",
    "        ],\n",
    "        vectorizers=[  # Add square brackets here\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"my-vectorizer\",  \n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    model_name=AzureOpenAIModelName.TEXT_EMBEDDING3_SMALL,\n",
    "                    deployment_name=\"text-embedding-3-small\",\n",
    "                    resource_url=\"https://fsunavala-openai-eus.openai.azure.com\",\n",
    "                    api_key=OPENAI_EMBEDDINGS_KEY,\n",
    "                ),\n",
    "            )\n",
    "        ],  # Close the list here\n",
    "        algorithms=[\n",
    "            ExhaustiveKnnAlgorithmConfiguration(name=\"my-eknn\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    new_index = SearchIndex(\n",
    "        name=MEMORY_INDEX_NAME,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "    )\n",
    "    try:\n",
    "        index_client.create_or_update_index(new_index)\n",
    "        print(f\"Index '{MEMORY_INDEX_NAME}' created or updated.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error creating/updating index '{MEMORY_INDEX_NAME}': {ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryTool:\n",
    "    def __init__(self, search_endpoint, search_api_key, index_name, embeddings_client: EmbeddingsClient):\n",
    "        self.search_endpoint = search_endpoint\n",
    "        self.search_api_key = search_api_key\n",
    "        self.index_name = index_name\n",
    "        self.embeddings_client = embeddings_client\n",
    "\n",
    "        self.search_client = SearchClient(\n",
    "            endpoint=self.search_endpoint,\n",
    "            index_name=self.index_name,\n",
    "            credential=AzureKeyCredential(self.search_api_key)\n",
    "        )\n",
    "\n",
    "    def _embed_text(self, text: str):\n",
    "        \"\"\"\n",
    "        Use azure.ai.inference.EmbeddingsClient to get embeddings for a single text string.\n",
    "        We'll assume single-element input for simplicity.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            resp = self.embeddings_client.embed(input=[text])\n",
    "        return resp.data[0].embedding\n",
    "\n",
    "    def store_memory(self, thread_id: str, role: str, content: str):\n",
    "        \"\"\"\n",
    "        Store (mergeOrUpload) a memory record in Azure AI Search.\n",
    "        \"\"\"\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        embedding_vector = self._embed_text(content)\n",
    "\n",
    "        doc = {\n",
    "            \"id\": doc_id,\n",
    "            \"threadId\": thread_id,\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            VECTOR_FIELD: embedding_vector\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            upload_result = self.search_client.merge_or_upload_documents(documents=[doc])\n",
    "            if upload_result and upload_result[0].succeeded:\n",
    "                print(f\"[MemoryTool] Stored memory doc with id={doc_id}, threadId={thread_id}\")\n",
    "            else:\n",
    "                print(f\"[MemoryTool] Failed to store memory doc. Partial result: {upload_result}\")\n",
    "        except Exception as e:\n",
    "            print(\"store_memory failed:\", e)\n",
    "\n",
    "        return doc_id\n",
    "\n",
    "    def retrieve_memories(self, thread_id: str, user_query: str, k: int = 3):\n",
    "        \"\"\"\n",
    "        Vector search for 'user_query', filtering on threadId eq <thread_id>.\n",
    "        The python SDK doesn't (yet) have a direct vector parameter, so we do a REST call ourselves.\n",
    "        \"\"\"\n",
    "        query_vector = self._embed_text(user_query)\n",
    "\n",
    "        body = {\n",
    "            \"vectorQueries\": [\n",
    "                {\n",
    "                    \"kind\": \"vector\",\n",
    "                    \"fields\": VECTOR_FIELD,\n",
    "                    \"value\": query_vector,\n",
    "                    \"k\": k\n",
    "                }\n",
    "            ],\n",
    "            \"filter\": f\"threadId eq '{thread_id}'\"\n",
    "        }\n",
    "\n",
    "        url = f\"{self.search_endpoint}/indexes('{self.index_name}')/docs/search.post.search?api-version=2024-11-01-preview\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": self.search_api_key\n",
    "        }\n",
    "        try:\n",
    "            resp = requests.post(url, headers=headers, json=body)\n",
    "            resp.raise_for_status()\n",
    "            results_json = resp.json()\n",
    "            return results_json.get(\"value\", [])\n",
    "        except Exception as e:\n",
    "            print(\"retrieve_memories failed:\", e)\n",
    "            return []\n",
    "\n",
    "    def update_memory(self, doc_id: str, new_content: str):\n",
    "        \"\"\"\n",
    "        Re-embed the new content, then merge_or_upload again to update it.\n",
    "        \"\"\"\n",
    "        new_embedding = self._embed_text(new_content)\n",
    "        doc = {\n",
    "            \"id\": doc_id,\n",
    "            \"content\": new_content,\n",
    "            VECTOR_FIELD: new_embedding\n",
    "        }\n",
    "        try:\n",
    "            update_result = self.search_client.merge_or_upload_documents(documents=[doc])\n",
    "            if update_result and update_result[0].succeeded:\n",
    "                print(f\"[MemoryTool] Updated memory doc_id={doc_id}\")\n",
    "            else:\n",
    "                print(f\"[MemoryTool] Partial update failure: {update_result}\")\n",
    "        except Exception as e:\n",
    "            print(\"update_memory failed:\", e)\n",
    "\n",
    "    def delete_memory(self, doc_id: str):\n",
    "        \"\"\"\n",
    "        Delete doc by doc_id.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            delete_result = self.search_client.delete_documents(documents=[{\"id\": doc_id}])\n",
    "            if delete_result and delete_result[0].succeeded:\n",
    "                print(f\"[MemoryTool] Deleted memory doc_id={doc_id}\")\n",
    "            else:\n",
    "                print(f\"[MemoryTool] Partial delete failure: {delete_result}\")\n",
    "        except Exception as e:\n",
    "            print(\"delete_memory failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'memory-index' created or updated.\n"
     ]
    }
   ],
   "source": [
    "create_or_update_memory_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIProjectClient created.\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# You can do AzureCliCredential or DefaultAzureCredential, etc.\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# 1) AIProjectClient\n",
    "client = AIProjectClient.from_connection_string(\n",
    "    credential=credential,\n",
    "    conn_str=AZURE_CONNECTION_STRING\n",
    ")\n",
    "print(\"AIProjectClient created.\")\n",
    "\n",
    "# 2) MemoryTool instance\n",
    "my_memory_tool = MemoryTool(\n",
    "    search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    search_api_key=AZURE_SEARCH_API_KEY,\n",
    "    index_name=MEMORY_INDEX_NAME,\n",
    "    embeddings_client=embeddings_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent: {'id': 'asst_QqdGgzGVoMVpEQxc2Ar3AG3p', 'object': 'assistant', 'created_at': 1741013165, 'name': 'memory-demo-assistant', 'description': None, 'model': 'gpt-4o', 'instructions': 'You are a helpful memory-enabled agent.', 'tools': [], 'top_p': 1.0, 'temperature': 1.0, 'tool_resources': {}, 'metadata': {}, 'response_format': 'auto'}\n",
      "Created thread: thread_Sr0vSDsUhQlUk9R6oeA0CvdC\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # We'll not strictly need a search tool here, but let's do a minimal example\n",
    "    agent = client.agents.create_agent(\n",
    "        model=\"gpt-4o\",  # or any valid deployment name\n",
    "        name=\"memory-demo-assistant\",\n",
    "        instructions=\"You are a helpful memory-enabled agent.\",\n",
    "        # tools=[],\n",
    "        # tool_resources=[]\n",
    "    )\n",
    "    print(\"Created agent:\", agent)\n",
    "\n",
    "    # create a new Thread\n",
    "    thread = client.agents.create_thread()\n",
    "    thread_id = thread.id\n",
    "    print(\"Created thread:\", thread_id)\n",
    "except Exception as e:\n",
    "    print(\"Agent/Thread creation error:\", e)\n",
    "    thread_id = str(uuid.uuid4())  # fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "(DeploymentNotFound) The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.\nCode: DeploymentNotFound\nMessage: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m user_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello! I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm planning a summer trip to Spain. I love outdoor hiking!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m user_doc_id \u001b[38;5;241m=\u001b[39m \u001b[43mmy_memory_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m assistant_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGreat! Spain has wonderful places to hike, like the Pyrenees.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m assistant_doc_id \u001b[38;5;241m=\u001b[39m my_memory_tool\u001b[38;5;241m.\u001b[39mstore_memory(thread_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, assistant_content)\n",
      "Cell \u001b[1;32mIn[43], line 28\u001b[0m, in \u001b[0;36mMemoryTool.store_memory\u001b[1;34m(self, thread_id, role, content)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03mStore (mergeOrUpload) a memory record in Azure AI Search.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m doc_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n\u001b[1;32m---> 28\u001b[0m embedding_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m doc \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc_id,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreadId\u001b[39m\u001b[38;5;124m\"\u001b[39m: thread_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     VECTOR_FIELD: embedding_vector\n\u001b[0;32m     36\u001b[0m }\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[43], line 19\u001b[0m, in \u001b[0;36mMemoryTool._embed_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_embed_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    Use azure.ai.inference.EmbeddingsClient to get embeddings for a single text string.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    We'll assume single-element input for simplicity.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# We'll get resp.data[0].embedding\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-agents-playground\\samples\\05-AGENTIC-RAG-QUERY-PLANNING\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-agents-playground\\samples\\05-AGENTIC-RAG-QUERY-PLANNING\\.venv\\Lib\\site-packages\\azure\\ai\\inference\\_patch.py:1034\u001b[0m, in \u001b[0;36mEmbeddingsClient.embed\u001b[1;34m(self, body, input, dimensions, encoding_format, input_type, model, model_extras, **kwargs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[0;32m   1033\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# Load the body in memory and close the socket\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n",
      "File \u001b[1;32mc:\\Dev\\azure-ai-agents-playground\\samples\\05-AGENTIC-RAG-QUERY-PLANNING\\.venv\\Lib\\site-packages\\azure\\core\\exceptions.py:163\u001b[0m, in \u001b[0;36mmap_error\u001b[1;34m(status_code, response, error_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    162\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[1;31mResourceNotFoundError\u001b[0m: (DeploymentNotFound) The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.\nCode: DeploymentNotFound\nMessage: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again."
     ]
    }
   ],
   "source": [
    "user_content = \"Hello! I'm planning a summer trip to Spain. I love outdoor hiking!\"\n",
    "user_doc_id = my_memory_tool.store_memory(thread_id, \"user\", user_content)\n",
    "\n",
    "assistant_content = \"Great! Spain has wonderful places to hike, like the Pyrenees.\"\n",
    "assistant_doc_id = my_memory_tool.store_memory(thread_id, \"assistant\", assistant_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Starting Memory Agent Demo\n",
      "✅ Memory index 'fact-memory-index' already exists\n",
      "✅ Testing search client connection...\n",
      "✅ Search client connection verified\n",
      "🤖 Memory agent created with ID: asst_BTmmgYfiVtab7EK4XnvCbCS1\n",
      "🆕 Started new conversation (Thread ID: thread_1aMyqdwxEjyQsVyHr37iXHnb)\n",
      "==================================================\n",
      "🧠 MEMORY-ENHANCED AGENT CONVERSATION\n",
      "==================================================\n",
      "Commands:\n",
      "  'exit' - End conversation\n",
      "  'facts' - List all stored facts\n",
      "  'memory on/off' - Toggle memory operation visibility\n",
      "==================================================\n",
      "⚠️ Input cannot be empty. Please try again.\n",
      "⏳ Processing...\n",
      "🔄 Run status: RunStatus.REQUIRES_ACTION\n",
      "\n",
      "📝 MEMORY STORED: [personal] User's name is Farzad\n",
      "----------------------------------------\n",
      "🛠️ Processing tool call: store_memory_func\n",
      "  - Arguments: {\"thread_id\":\"89a4e85a-267f-4136-8733-7f5a6940b719\",\"content\":\"User's name is Farzad\",\"fact_type\":\"personal\",\"confidence\":\"1.0\"}\n",
      "🛠️ Tool called: store_memory_func\n",
      "  - Thread ID: 89a4e85a-267f-4136-8733-7f5a6940b719\n",
      "  - Content: User's name is Farzad\n",
      "  - Fact type: personal\n",
      "  - Confidence: 1.0\n",
      "⚠️ Thread ID mismatch! Using thread_1aMyqdwxEjyQsVyHr37iXHnb instead of 89a4e85a-267f-4136-8733-7f5a6940b719\n",
      "💾 STORED: [fact] User's name is Farzad\n",
      "📤 Submitting 1 tool outputs\n",
      "📊 MEMORY OPERATIONS SUMMARY: stored new fact\n",
      "🔄 Run status: RunStatus.COMPLETED\n",
      "\n",
      "🤖 Assistant: {'type': 'text', 'text': {'value': 'Hi Farzad! How can I assist you today?', 'annotations': []}}\n",
      "⚠️ Input cannot be empty. Please try again.\n",
      "⚠️ Input cannot be empty. Please try again.\n",
      "\n",
      "👋 Conversation ended. Thread ID: thread_1aMyqdwxEjyQsVyHr37iXHnb\n",
      "\n",
      "🔍 Would you like to see all stored facts? (y/n)\n",
      "\n",
      "✨ Memory Agent Demo completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "    This sample demonstrates how to use Azure AI Search as a 'MemoryTool' with \n",
    "    Azure Agent Service, leveraging the Tool Function Calling lifecycle with\n",
    "    structured output via Pydantic models.\n",
    "\n",
    "USAGE:\n",
    "    python sample_agents_memory_search.py\n",
    "\n",
    "    Before running the sample:\n",
    "\n",
    "    pip install azure-ai-projects azure-identity azure-search-documents pydantic\n",
    "\n",
    "    Set these environment variables with your own values:\n",
    "    1) AZURE_CONNECTION_STRING - The project connection string\n",
    "    2) AZURE_SEARCH_SERVICE_ENDPOINT - The endpoint of your Azure Search service\n",
    "    3) AZURE_SEARCH_ADMIN_KEY - The admin key for your Azure Search service\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import re\n",
    "from datetime import datetime, UTC\n",
    "from typing import List, Dict, Any, Optional, Union, Set, Callable\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    FunctionTool,\n",
    "    ToolSet,\n",
    "    RequiredFunctionToolCall,\n",
    "    SubmitToolOutputsAction,\n",
    "    ToolOutput,\n",
    "    RunStatus,\n",
    "    ResponseFormatJsonSchema,\n",
    "    ResponseFormatJsonSchemaType,\n",
    ")\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Configuration\n",
    "AZURE_CONNECTION_STRING = os.getenv(\"AZURE_CONNECTION_STRING\")\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "AZURE_SEARCH_ADMIN_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "MEMORY_INDEX_NAME = \"fact-memory-index\"\n",
    "DEBUG_MODE = True  # Set to False to disable debug output\n",
    "MEMORY_LIMIT = 3  # Default limit for memory retrieval\n",
    "CORRECT_THREAD_ID = None  # Will be set when conversation starts\n",
    "\n",
    "# Initialize clients\n",
    "search_client = SearchClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    index_name=MEMORY_INDEX_NAME,\n",
    "    credential=AzureKeyCredential(AZURE_SEARCH_ADMIN_KEY),\n",
    ")\n",
    "\n",
    "projects_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=AZURE_CONNECTION_STRING,\n",
    ")\n",
    "\n",
    "# Define Pydantic models for structured outputs\n",
    "class FactType(str, Enum):\n",
    "    PERSONAL = \"personal\"\n",
    "    PREFERENCE = \"preference\"\n",
    "    PLAN = \"plan\"\n",
    "    CONTACT = \"contact\"\n",
    "    WORK = \"work\"\n",
    "    OTHER = \"other\"\n",
    "\n",
    "class Fact(BaseModel):\n",
    "    content: str = Field(..., description=\"The fact content\")\n",
    "    fact_type: FactType = Field(..., description=\"The type of fact\")\n",
    "    confidence: float = Field(\n",
    "        ..., description=\"Confidence score for this fact (0.0-1.0)\", ge=0.0, le=1.0\n",
    "    )\n",
    "\n",
    "class FactExtraction(BaseModel):\n",
    "    facts: List[Fact] = Field(..., description=\"List of extracted facts\")\n",
    "\n",
    "# Helper function to properly extract text from messages\n",
    "def extract_text(content):\n",
    "    \"\"\"\n",
    "    Extract clean text from various message formats.\n",
    "    Handles all observed formats in the console output.\n",
    "    \"\"\"\n",
    "    # Handle string content\n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "\n",
    "    # Handle dict with nested structure - most common format from output\n",
    "    if isinstance(content, dict):\n",
    "        # Check for the structure {'type': 'text', 'text': {'value': \"...\"}}\n",
    "        if content.get(\"type\") == \"text\" and isinstance(content.get(\"text\"), dict):\n",
    "            return content[\"text\"].get(\"value\", \"\")\n",
    "\n",
    "        # Check for other nested structures\n",
    "        if \"text\" in content:\n",
    "            if isinstance(content[\"text\"], dict) and \"value\" in content[\"text\"]:\n",
    "                return content[\"text\"][\"value\"]\n",
    "            return str(content[\"text\"])\n",
    "        elif \"value\" in content:\n",
    "            return str(content[\"value\"])\n",
    "\n",
    "    # Handle list content\n",
    "    if isinstance(content, list) and len(content) > 0:\n",
    "        # Recursively extract from first item if it's a list\n",
    "        return extract_text(content[0])\n",
    "\n",
    "    # Default fallback\n",
    "    return str(content)\n",
    "\n",
    "# Ensure memory index exists\n",
    "def ensure_memory_index_exists():\n",
    "    \"\"\"Create or update the memory index if it doesn't exist\"\"\"\n",
    "    try:\n",
    "        # Initialize the search index client\n",
    "        index_client = SearchIndexClient(\n",
    "            endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "            credential=AzureKeyCredential(AZURE_SEARCH_ADMIN_KEY),\n",
    "        )\n",
    "\n",
    "        # Check if index exists\n",
    "        index_exists = False\n",
    "        try:\n",
    "            index_info = index_client.get_index(name=MEMORY_INDEX_NAME)\n",
    "            index_exists = True\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"✅ Memory index '{MEMORY_INDEX_NAME}' already exists\")\n",
    "        except:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"🔧 Creating memory index '{MEMORY_INDEX_NAME}'...\")\n",
    "\n",
    "        # If index doesn't exist, create it\n",
    "        if not index_exists:\n",
    "            # Define the index fields\n",
    "            fields = [\n",
    "                SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "                SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "                SimpleField(\n",
    "                    name=\"thread_id\", type=SearchFieldDataType.String, filterable=True\n",
    "                ),\n",
    "                SimpleField(\n",
    "                    name=\"fact_type\", type=SearchFieldDataType.String, filterable=True\n",
    "                ),\n",
    "                SimpleField(\n",
    "                    name=\"confidence\", type=SearchFieldDataType.Double, filterable=True\n",
    "                ),\n",
    "                SimpleField(\n",
    "                    name=\"timestamp\",\n",
    "                    type=SearchFieldDataType.DateTimeOffset,\n",
    "                    filterable=True,\n",
    "                    sortable=True,\n",
    "                ),\n",
    "            ]\n",
    "\n",
    "            # Create the index definition\n",
    "            index = SearchIndex(name=MEMORY_INDEX_NAME, fields=fields)\n",
    "\n",
    "            # Create the index\n",
    "            index_client.create_or_update_index(index)\n",
    "\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"✅ Created memory index '{MEMORY_INDEX_NAME}'\")\n",
    "\n",
    "        # Test search client connection\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"✅ Testing search client connection...\")\n",
    "            try:\n",
    "                test_result = search_client.search(search_text=\"*\", top=1)\n",
    "                list(test_result)  # Force evaluation\n",
    "                print(f\"✅ Search client connection verified\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ ERROR with search client: {e}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        if DEBUG_MODE:\n",
    "            print(f\"❌ ERROR creating memory index: {e}\")\n",
    "        return False\n",
    "\n",
    "# Define memory management functions for agent\n",
    "def create_memory_functions():\n",
    "    \"\"\"Define memory management functions\"\"\"\n",
    "\n",
    "    # CREATE memory function\n",
    "    def store_memory_func(thread_id, content, fact_type=\"other\", confidence=1.0):\n",
    "        \"\"\"Store a new fact in memory\"\"\"\n",
    "        global CORRECT_THREAD_ID\n",
    "\n",
    "        try:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"🛠️ Tool called: store_memory_func\")\n",
    "                print(f\"  - Thread ID: {thread_id}\")\n",
    "                print(\n",
    "                    f\"  - Content: {content[:50]}...\"\n",
    "                    if len(content) > 50\n",
    "                    else f\"  - Content: {content}\"\n",
    "                )\n",
    "                print(f\"  - Fact type: {fact_type}\")\n",
    "                print(f\"  - Confidence: {confidence}\")\n",
    "\n",
    "            # Always use the correct thread_id\n",
    "            if CORRECT_THREAD_ID and thread_id != CORRECT_THREAD_ID:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\n",
    "                        f\"⚠️ Thread ID mismatch! Using {CORRECT_THREAD_ID} instead of {thread_id}\"\n",
    "                    )\n",
    "                thread_id = CORRECT_THREAD_ID\n",
    "\n",
    "            doc_id = str(uuid.uuid4())\n",
    "            doc = {\n",
    "                \"id\": doc_id,\n",
    "                \"thread_id\": thread_id,\n",
    "                \"content\": content,\n",
    "                \"fact_type\": fact_type,\n",
    "                \"confidence\": confidence,\n",
    "                \"timestamp\": datetime.now(UTC),\n",
    "            }\n",
    "\n",
    "            result = search_client.upload_documents([doc])\n",
    "\n",
    "            if DEBUG_MODE:\n",
    "                print(\n",
    "                    f\"💾 STORED: [fact] {content[:50]}...\"\n",
    "                    if len(content) > 50\n",
    "                    else f\"💾 STORED: [fact] {content}\"\n",
    "                )\n",
    "\n",
    "            return json.dumps({\"id\": doc_id, \"status\": \"success\"})\n",
    "        except Exception as e:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"❌ ERROR storing fact: {e}\")\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "\n",
    "    # READ memory function\n",
    "    def retrieve_memories_func(\n",
    "        thread_id, query=\"\", limit=MEMORY_LIMIT, min_confidence=0.0\n",
    "    ):\n",
    "        \"\"\"Retrieve relevant facts from memory\"\"\"\n",
    "        global CORRECT_THREAD_ID\n",
    "\n",
    "        try:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"🛠️ Tool called: retrieve_memories_func\")\n",
    "                print(f\"  - Thread ID: {thread_id}\")\n",
    "                print(f\"  - Query: '{query}'\")\n",
    "                print(f\"  - Limit: {limit}\")\n",
    "                print(f\"  - Min confidence: {min_confidence}\")\n",
    "\n",
    "            # Always use the correct thread_id\n",
    "            if CORRECT_THREAD_ID and thread_id != CORRECT_THREAD_ID:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\n",
    "                        f\"⚠️ Thread ID mismatch! Using {CORRECT_THREAD_ID} instead of {thread_id}\"\n",
    "                    )\n",
    "                thread_id = CORRECT_THREAD_ID\n",
    "\n",
    "            filter_expr = f\"thread_id eq '{thread_id}' and confidence ge {min_confidence}\"\n",
    "\n",
    "            if query:\n",
    "                # Semantic search with filter\n",
    "                results = search_client.search(\n",
    "                    search_text=query,\n",
    "                    filter=filter_expr,\n",
    "                    top=limit,\n",
    "                    select=\"id,content,fact_type,confidence,timestamp\",\n",
    "                )\n",
    "                if DEBUG_MODE:\n",
    "                    print(f\"🔍 Retrieving memories for query: '{query}'\")\n",
    "            else:\n",
    "                # Get most recent facts\n",
    "                results = search_client.search(\n",
    "                    search_text=\"*\",\n",
    "                    filter=filter_expr,\n",
    "                    top=limit,\n",
    "                    order_by=\"timestamp desc\",\n",
    "                    select=\"id,content,fact_type,confidence,timestamp\",\n",
    "                )\n",
    "                if DEBUG_MODE:\n",
    "                    print(f\"🔍 Retrieving {limit} most recent memories\")\n",
    "\n",
    "            memories = []\n",
    "            for r in results:\n",
    "                memories.append(\n",
    "                    {\n",
    "                        \"id\": r.get(\"id\", \"\"),\n",
    "                        \"content\": r.get(\"content\", \"\"),\n",
    "                        \"fact_type\": r.get(\"fact_type\", \"other\"),\n",
    "                        \"confidence\": r.get(\"confidence\", 1.0),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if DEBUG_MODE and memories:\n",
    "                print(f\"🔍 Retrieved {len(memories)} memories\")\n",
    "\n",
    "            return json.dumps({\"memories\": memories, \"count\": len(memories)})\n",
    "        except Exception as e:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"❌ ERROR retrieving memories: {e}\")\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "\n",
    "    # UPDATE memory function\n",
    "    def update_memory_func(\n",
    "        thread_id, memory_id, new_content, fact_type=None, confidence=None\n",
    "    ):\n",
    "        \"\"\"Update an existing fact in memory\"\"\"\n",
    "        global CORRECT_THREAD_ID\n",
    "\n",
    "        try:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"🛠️ Tool called: update_memory_func\")\n",
    "                print(f\"  - Thread ID: {thread_id}\")\n",
    "                print(f\"  - Memory ID: {memory_id}\")\n",
    "                print(\n",
    "                    f\"  - New content: {new_content[:50]}...\"\n",
    "                    if len(new_content) > 50\n",
    "                    else f\"  - New content: {new_content}\"\n",
    "                )\n",
    "\n",
    "            # Always use the correct thread_id\n",
    "            if CORRECT_THREAD_ID and thread_id != CORRECT_THREAD_ID:\n",
    "                if DEBUG_MODE:\n",
    "                    print(\n",
    "                        f\"⚠️ Thread ID mismatch! Using {CORRECT_THREAD_ID} instead of {thread_id}\"\n",
    "                    )\n",
    "                thread_id = CORRECT_THREAD_ID\n",
    "\n",
    "            # First retrieve the existing document\n",
    "            try:\n",
    "                existing_doc = search_client.get_document(key=memory_id)\n",
    "            except Exception as e:\n",
    "                if DEBUG_MODE:\n",
    "                    print(f\"❌ ERROR retrieving document for update: {e}\")\n",
    "                return json.dumps({\"error\": f\"Document with ID {memory_id} not found\"})\n",
    "\n",
    "            # Prepare the updated document\n",
    "            doc = {\n",
    "                \"id\": memory_id,\n",
    "                \"thread_id\": thread_id,\n",
    "                \"content\": new_content,\n",
    "                \"fact_type\": fact_type or existing_doc.get(\"fact_type\", \"other\"),\n",
    "                \"confidence\": confidence or existing_doc.get(\"confidence\", 1.0),\n",
    "                \"timestamp\": datetime.now(UTC),\n",
    "            }\n",
    "\n",
    "            # Update the document\n",
    "            result = search_client.merge_documents([doc])\n",
    "\n",
    "            if DEBUG_MODE:\n",
    "                print(\n",
    "                    f\"✏️ UPDATED: [fact] {new_content[:50]}...\"\n",
    "                    if len(new_content) > 50\n",
    "                    else f\"✏️ UPDATED: [fact] {new_content}\"\n",
    "                )\n",
    "\n",
    "            return json.dumps({\"id\": memory_id, \"status\": \"updated\"})\n",
    "        except Exception as e:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"❌ ERROR updating memory: {e}\")\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "\n",
    "    # DELETE memory function\n",
    "    def delete_memory_func(memory_id):\n",
    "        \"\"\"Delete a fact from memory\"\"\"\n",
    "        try:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"🛠️ Tool called: delete_memory_func\")\n",
    "                print(f\"  - Memory ID: {memory_id}\")\n",
    "\n",
    "            # Delete the document\n",
    "            search_client.delete_documents([{\"id\": memory_id}])\n",
    "\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"🗑️ DELETED: [fact] {memory_id}\")\n",
    "\n",
    "            return json.dumps({\"id\": memory_id, \"status\": \"deleted\"})\n",
    "        except Exception as e:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"❌ ERROR deleting memory: {e}\")\n",
    "            return json.dumps({\"error\": str(e)})\n",
    "\n",
    "    return {\n",
    "        store_memory_func,\n",
    "        retrieve_memories_func,\n",
    "        update_memory_func,\n",
    "        delete_memory_func,\n",
    "    }\n",
    "\n",
    "# Log memory operations (always visible regardless of DEBUG_MODE)\n",
    "def log_memory_operation(operation, details=None):\n",
    "    \"\"\"Log memory operations with prominent visibility\"\"\"\n",
    "    if operation == \"store\":\n",
    "        print(f\"\\n📝 MEMORY STORED: {details}\")\n",
    "    elif operation == \"retrieve\":\n",
    "        if isinstance(details, int):\n",
    "            print(f\"\\n🔍 MEMORIES RETRIEVED: {details} fact(s)\")\n",
    "        else:\n",
    "            print(f\"\\n🔍 MEMORIES RETRIEVED: {details}\")\n",
    "    elif operation == \"update\":\n",
    "        print(f\"\\n✏️ MEMORY UPDATED: {details}\")\n",
    "    elif operation == \"delete\":\n",
    "        print(f\"\\n🗑️ MEMORY DELETED: ID {details}\")\n",
    "    else:\n",
    "        print(f\"\\n📊 MEMORY OPERATION [{operation}]: {details}\")\n",
    "    \n",
    "    # Add separator for visibility\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Process function calls from the agent\n",
    "def process_function_calls(thread_id, run_id, tool_calls):\n",
    "    \"\"\"Process function calls from the agent and submit tool outputs\"\"\"\n",
    "    try:\n",
    "        memory_functions = create_memory_functions()\n",
    "        function_tool = FunctionTool(memory_functions)\n",
    "\n",
    "        tool_outputs = []\n",
    "        memory_ops_summary = []\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                try:\n",
    "                    function_name = tool_call.function.name\n",
    "                    arguments = tool_call.function.arguments\n",
    "                    \n",
    "                    # Always show when memory functions are called (regardless of DEBUG_MODE)\n",
    "                    if function_name == \"store_memory_func\":\n",
    "                        args = json.loads(arguments)\n",
    "                        content = args.get(\"content\", \"\")\n",
    "                        fact_type = args.get(\"fact_type\", \"other\")\n",
    "                        log_memory_operation(\"store\", f\"[{fact_type}] {content[:100]}\" + (\"...\" if len(content) > 100 else \"\"))\n",
    "                        memory_ops_summary.append(\"stored new fact\")\n",
    "                    \n",
    "                    elif function_name == \"retrieve_memories_func\":\n",
    "                        args = json.loads(arguments)\n",
    "                        query = args.get(\"query\", \"\")\n",
    "                        if query:\n",
    "                            log_memory_operation(\"retrieve\", f\"Query: '{query}'\")\n",
    "                        else:\n",
    "                            log_memory_operation(\"retrieve\", \"Recent facts\")\n",
    "                        memory_ops_summary.append(\"retrieved facts\")\n",
    "                    \n",
    "                    elif function_name == \"update_memory_func\":\n",
    "                        args = json.loads(arguments)\n",
    "                        memory_id = args.get(\"memory_id\", \"\")\n",
    "                        new_content = args.get(\"new_content\", \"\")\n",
    "                        log_memory_operation(\"update\", f\"ID {memory_id[:8]}... - {new_content[:100]}\" + (\"...\" if len(new_content) > 100 else \"\"))\n",
    "                        memory_ops_summary.append(\"updated fact\")\n",
    "                    \n",
    "                    elif function_name == \"delete_memory_func\":\n",
    "                        args = json.loads(arguments)\n",
    "                        memory_id = args.get(\"memory_id\", \"\")\n",
    "                        log_memory_operation(\"delete\", memory_id)\n",
    "                        memory_ops_summary.append(\"deleted fact\")\n",
    "                    \n",
    "                    if DEBUG_MODE:\n",
    "                        print(f\"🛠️ Processing tool call: {function_name}\")\n",
    "                        print(f\"  - Arguments: {arguments}\")\n",
    "\n",
    "                    # Execute the function\n",
    "                    output = function_tool.execute(tool_call)\n",
    "                    \n",
    "                    # For retrieve_memories_func, show how many memories were retrieved\n",
    "                    if function_name == \"retrieve_memories_func\":\n",
    "                        try:\n",
    "                            result = json.loads(output)\n",
    "                            if \"memories\" in result and \"count\" in result:\n",
    "                                count = result[\"count\"]\n",
    "                                log_memory_operation(\"retrieve\", f\"{count} fact(s) returned\")\n",
    "                                \n",
    "                                # If facts were retrieved, show them\n",
    "                                if count > 0 and not DEBUG_MODE:  # In debug mode we already show them\n",
    "                                    print(\"📋 Retrieved facts:\")\n",
    "                                    for i, memory in enumerate(result[\"memories\"]):\n",
    "                                        print(f\"  {i+1}. [{memory.get('fact_type', 'other')}] {memory.get('content', '')}\")\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    tool_outputs.append(\n",
    "                        ToolOutput(tool_call_id=tool_call.id, output=output)\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error executing tool call {tool_call.id}: {e}\")\n",
    "\n",
    "        if tool_outputs:\n",
    "            if DEBUG_MODE:\n",
    "                print(f\"📤 Submitting {len(tool_outputs)} tool outputs\")\n",
    "\n",
    "            projects_client.agents.submit_tool_outputs_to_run(\n",
    "                thread_id=thread_id, run_id=run_id, tool_outputs=tool_outputs\n",
    "            )\n",
    "            \n",
    "            if memory_ops_summary:\n",
    "                print(f\"📊 MEMORY OPERATIONS SUMMARY: {', '.join(memory_ops_summary)}\")\n",
    "\n",
    "        return len(tool_outputs)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing function calls: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Create memory agent with function calling\n",
    "def create_memory_agent():\n",
    "    \"\"\"Create agent with memory management functions\"\"\"\n",
    "\n",
    "    # Initialize the memory functions\n",
    "    memory_functions = create_memory_functions()\n",
    "\n",
    "    # Create a function tool with the memory functions\n",
    "    function_tool = FunctionTool(memory_functions)\n",
    "\n",
    "    # Create agent with complete memory management instructions\n",
    "    agent = projects_client.agents.create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        name=f\"memory-agent-{uuid.uuid4().hex[:6]}\",\n",
    "        instructions=\"\"\"You are an assistant with memory management capabilities.\n",
    "\n",
    "IMPORTANT: At the start of each conversation, ALWAYS use retrieve_memories_func to check what you know about the user.\n",
    "\n",
    "You have access to four memory management functions:\n",
    "1. store_memory_func(thread_id, content, fact_type, confidence) - Store a new fact about the user\n",
    "2. retrieve_memories_func(thread_id, query, limit, min_confidence) - Retrieve relevant facts\n",
    "3. update_memory_func(thread_id, memory_id, new_content, fact_type, confidence) - Update an existing fact\n",
    "4. delete_memory_func(memory_id) - Delete a fact that is no longer relevant\n",
    "\n",
    "When interacting with users:\n",
    "1. ALWAYS begin by retrieving and reviewing relevant memories using retrieve_memories_func\n",
    "2. When users share important information about themselves, IMMEDIATELY store it using store_memory_func\n",
    "3. If information needs updating, use update_memory_func to keep facts current\n",
    "4. Use the fact_type parameter to categorize facts (personal, preference, plan, contact, work, other)\n",
    "5. Use the confidence parameter (0.0-1.0) to indicate how certain you are about a fact\n",
    "\n",
    "CRITICAL: The thread_id must ALWAYS be the EXACT thread_id that was provided to you. \n",
    "Never modify, shorten, or create your own thread_id. Always use the full thread_id exactly as given.\n",
    "\n",
    "Examples of facts to store:\n",
    "- Personal facts: \"User's name is Alex\", \"User is 32 years old\"\n",
    "- Preferences: \"User prefers vegetarian food\", \"User enjoys hiking\"\n",
    "- Plans: \"User is planning a trip to Japan in June\", \"User has a meeting tomorrow\"\n",
    "- Work: \"User works as a software engineer\", \"User is working on a data analysis project\"\n",
    "\n",
    "Be proactive in memory management - don't wait for explicit instructions to store facts.\n",
    "NEVER mention the memory system to users - just naturally incorporate what you know.\"\"\",\n",
    "        tools=function_tool.definitions,\n",
    "    )\n",
    "\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"🤖 Memory agent created with ID: {agent.id}\")\n",
    "\n",
    "    return agent\n",
    "\n",
    "# Start conversation with memory agent\n",
    "def start_conversation(existing_thread_id=None):\n",
    "    \"\"\"Start a conversation with the memory agent\"\"\"\n",
    "    # Ensure memory index exists before proceeding\n",
    "    if not ensure_memory_index_exists():\n",
    "        print(\"❌ Failed to create or verify memory index. Exiting.\")\n",
    "        return\n",
    "        \n",
    "    # Create memory agent\n",
    "    memory_agent = create_memory_agent()\n",
    "\n",
    "    # Create or continue thread and set global thread_id\n",
    "    global CORRECT_THREAD_ID\n",
    "    if existing_thread_id:\n",
    "        thread_id = existing_thread_id\n",
    "        CORRECT_THREAD_ID = thread_id\n",
    "        print(f\"🔄 Continuing conversation with Thread ID: {thread_id}\")\n",
    "    else:\n",
    "        thread = projects_client.agents.create_thread()\n",
    "        thread_id = thread.id\n",
    "        CORRECT_THREAD_ID = thread_id\n",
    "        print(f\"🆕 Started new conversation (Thread ID: {thread_id})\")\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"🧠 MEMORY-ENHANCED AGENT CONVERSATION\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Commands:\")\n",
    "    print(\"  'exit' - End conversation\")\n",
    "    print(\"  'facts' - List all stored facts\")\n",
    "    print(\"  'memory on/off' - Toggle memory operation visibility\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Flag to control memory operation visibility\n",
    "    show_memory_ops = True\n",
    "\n",
    "    # Main conversation loop\n",
    "    show_memory_ops = True  # Flag to control memory operation visibility\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\n😀 You: \").strip()\n",
    "        if not user_input:\n",
    "            print(\"⚠️ Input cannot be empty. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        # Handle special commands\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "            \n",
    "        if user_input.lower() in [\"facts\", \"list facts\", \"show facts\"]:\n",
    "            list_all_facts(thread_id)\n",
    "            continue\n",
    "            \n",
    "        if user_input.lower() == \"memory on\":\n",
    "            show_memory_ops = True\n",
    "            global DEBUG_MODE\n",
    "            DEBUG_MODE = True\n",
    "            print(\"🔔 Memory operations will now be shown\")\n",
    "            continue\n",
    "            \n",
    "        if user_input.lower() == \"memory off\":\n",
    "            show_memory_ops = False\n",
    "            DEBUG_MODE = False\n",
    "            print(\"🔕 Memory operations will be hidden\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Add message to thread\n",
    "            projects_client.agents.create_message(\n",
    "                thread_id=thread_id, role=\"user\", content=user_input\n",
    "            )\n",
    "\n",
    "            if DEBUG_MODE:\n",
    "                print(\"⏳ Processing...\")\n",
    "\n",
    "            # Create a run\n",
    "            run = projects_client.agents.create_run(\n",
    "                thread_id=thread_id, assistant_id=memory_agent.id\n",
    "            )\n",
    "\n",
    "            # Process the run and handle any function calls\n",
    "            while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "                time.sleep(1)\n",
    "                run = projects_client.agents.get_run(thread_id=thread_id, run_id=run.id)\n",
    "\n",
    "                if DEBUG_MODE:\n",
    "                    print(f\"🔄 Run status: {run.status}\")\n",
    "\n",
    "                if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "                    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "                    if tool_calls:\n",
    "                        process_function_calls(thread_id, run.id, tool_calls)\n",
    "\n",
    "            if run.status != RunStatus.COMPLETED:\n",
    "                if DEBUG_MODE:\n",
    "                    print(f\"❌ Run completed with non-success status: {run.status}\")\n",
    "\n",
    "            # Get assistant response\n",
    "            messages = projects_client.agents.list_messages(thread_id=thread_id)\n",
    "            latest = None\n",
    "\n",
    "            for msg in messages.data:\n",
    "                if msg.role == \"assistant\" and (\n",
    "                    not latest or msg.created_at > latest.created_at\n",
    "                ):\n",
    "                    latest = msg\n",
    "\n",
    "            if latest:\n",
    "                # Extract and display clean text\n",
    "                response_text = extract_text(latest.content)\n",
    "                print(f\"\\n🤖 Assistant: {response_text}\")\n",
    "                \n",
    "                # Show summary of memory usage for this turn\n",
    "                if run.required_action and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "                    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "                    memory_ops = {\n",
    "                        \"retrieve\": 0,\n",
    "                        \"store\": 0,\n",
    "                        \"update\": 0,\n",
    "                        \"delete\": 0\n",
    "                    }\n",
    "                    \n",
    "                    for tool_call in tool_calls:\n",
    "                        if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                            if tool_call.function.name == \"retrieve_memories_func\":\n",
    "                                memory_ops[\"retrieve\"] += 1\n",
    "                            elif tool_call.function.name == \"store_memory_func\":\n",
    "                                memory_ops[\"store\"] += 1\n",
    "                            elif tool_call.function.name == \"update_memory_func\":\n",
    "                                memory_ops[\"update\"] += 1\n",
    "                            elif tool_call.function.name == \"delete_memory_func\":\n",
    "                                memory_ops[\"delete\"] += 1\n",
    "                    \n",
    "                    # Show summary only if there were memory operations\n",
    "                    if sum(memory_ops.values()) > 0:\n",
    "                        print(\"\\n📊 MEMORY USAGE THIS TURN:\")\n",
    "                        if memory_ops[\"retrieve\"] > 0:\n",
    "                            print(f\"  • Retrieved facts: {memory_ops['retrieve']} time(s)\")\n",
    "                        if memory_ops[\"store\"] > 0:\n",
    "                            print(f\"  • Stored new facts: {memory_ops['store']} time(s)\")\n",
    "                        if memory_ops[\"update\"] > 0:\n",
    "                            print(f\"  • Updated facts: {memory_ops['update']} time(s)\")\n",
    "                        if memory_ops[\"delete\"] > 0:\n",
    "                            print(f\"  • Deleted facts: {memory_ops['delete']} time(s)\")\n",
    "            else:\n",
    "                print(\"❌ No response received.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # Clean up and return thread_id\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"\\n👋 Conversation ended. Thread ID: {thread_id}\")\n",
    "    \n",
    "    return thread_id\n",
    "\n",
    "# List all facts in memory\n",
    "def list_all_facts(thread_id):\n",
    "    \"\"\"List all facts stored for a thread\"\"\"\n",
    "    try:\n",
    "        # Ensure we use the correct thread_id\n",
    "        global CORRECT_THREAD_ID\n",
    "        if CORRECT_THREAD_ID:\n",
    "            thread_id = CORRECT_THREAD_ID\n",
    "\n",
    "        # Get all facts for this thread\n",
    "        results = search_client.search(\n",
    "            search_text=\"*\",\n",
    "            filter=f\"thread_id eq '{thread_id}'\",\n",
    "            top=100,\n",
    "            order_by=\"timestamp desc\",\n",
    "            select=\"id,content,fact_type,confidence,timestamp\",\n",
    "        )\n",
    "\n",
    "        facts = list(results)\n",
    "\n",
    "        print(\"\\n📋 ALL STORED FACTS:\")\n",
    "        if not facts:\n",
    "            print(f\"No facts found for thread ID: {thread_id}\")\n",
    "        else:\n",
    "            for i, fact in enumerate(facts):\n",
    "                fact_type = fact.get(\"fact_type\", \"other\")\n",
    "                confidence = fact.get(\"confidence\", 1.0)\n",
    "                print(\n",
    "                    f\"{i+1}. [{fact_type} - {confidence:.2f}] {fact.get('content', '')}\"\n",
    "                )\n",
    "\n",
    "        return facts\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR listing facts: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"🧠 Starting Memory Agent Demo\")\n",
    "        thread_id = start_conversation()\n",
    "        \n",
    "        # List all stored facts at the end\n",
    "        print(\"\\n🔍 Would you like to see all stored facts? (y/n)\")\n",
    "        if input().lower() == 'y':\n",
    "            list_all_facts(thread_id)\n",
    "            \n",
    "        print(\"\\n✨ Memory Agent Demo completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
